{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5155304f",
   "metadata": {},
   "source": [
    "# Starter Code for Modules 1, 2, and 3 Research Discussions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd35bce",
   "metadata": {},
   "source": [
    "\n",
    "## Module 1: Evaluating the Effectiveness of Pre-trained Models from Different Hubs\n",
    "\n",
    "In this module, you will explore and evaluate pre-trained models from Kaggle, PyTorch Hub, TensorFlow Hub, and Hugging Face. Consider the performance, computational resources, and suitability for specific tasks.\n",
    "\n",
    "### Starter Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b582dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Using cache found in C:\\Users\\zhatz/.cache\\torch\\hub\\pytorch_vision_v0.16.0\n",
      "c:\\Users\\zhatz\\Documents\\GitHub\\Data-Science-Masters\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zhatz\\Documents\\GitHub\\Data-Science-Masters\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998748302459717}]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# TensorFlow Hub Example\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[0;32m     13\u001b[0m tf_model \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf_model)\n",
      "File \u001b[1;32mc:\\Users\\zhatz\\Documents\\GitHub\\Data-Science-Masters\\.venv\\Lib\\site-packages\\tensorflow_hub\\__init__.py:85\u001b[0m\n\u001b[0;32m     74\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (parse_version(tf\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m\n\u001b[0;32m     75\u001b[0m       parse_version(required_tensorflow_version)):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis version of tensorflow_hub requires tensorflow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion >= \u001b[39m\u001b[38;5;132;01m{required}\u001b[39;00m\u001b[38;5;124m; Detected an installation of version \u001b[39m\u001b[38;5;132;01m{present}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m             required\u001b[38;5;241m=\u001b[39mrequired_tensorflow_version,\n\u001b[0;32m     83\u001b[0m             present\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39m__version__))\n\u001b[1;32m---> 85\u001b[0m \u001b[43m_ensure_tf_install\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_keras_2_importable\u001b[39m():\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Check that Keras 2 can be used by attempting to import tf_keras.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    ImportError: if using tf.keras would mean using Keras 3 and tf_keras is not\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m      installed.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhatz\\Documents\\GitHub\\Data-Science-Masters\\.venv\\Lib\\site-packages\\tensorflow_hub\\__init__.py:74\u001b[0m, in \u001b[0;36m_ensure_tf_install\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Update this whenever we need to depend on a newer TensorFlow release.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# and character class transitions.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     73\u001b[0m required_tensorflow_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.15.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (parse_version(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m) \u001b[38;5;241m<\u001b[39m\n\u001b[0;32m     75\u001b[0m     parse_version(required_tensorflow_version)):\n\u001b[0;32m     76\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis version of tensorflow_hub requires tensorflow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion >= \u001b[39m\u001b[38;5;132;01m{required}\u001b[39;00m\u001b[38;5;124m; Detected an installation of version \u001b[39m\u001b[38;5;132;01m{present}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m           required\u001b[38;5;241m=\u001b[39mrequired_tensorflow_version,\n\u001b[0;32m     83\u001b[0m           present\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39m__version__))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hugging Face Example\n",
    "from transformers import pipeline\n",
    "nlp_classifier = pipeline(\"sentiment-analysis\")\n",
    "print(nlp_classifier(\"This is a great movie!\"))\n",
    "\n",
    "# PyTorch Hub Example\n",
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.16.0', 'resnet50', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# TensorFlow Hub Example\n",
    "import tensorflow_hub as hub\n",
    "tf_model = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\")\n",
    "print(tf_model)\n",
    "\n",
    "# Kaggle Example - (assume Kaggle API is configured)\n",
    "# !kaggle datasets download -d zalando-research/fashionmnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0aec63c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde714fe",
   "metadata": {},
   "source": [
    "\n",
    "## Module 2: Impact of Data Preprocessing Techniques on Model Accuracy\n",
    "\n",
    "In this module, you will evaluate various preprocessing steps like data cleaning, normalization, handling missing values, and outlier detection using an example dataset.\n",
    "\n",
    "### Starter Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3b0b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target)\n",
    "\n",
    "# Introduce an artificial missing value (for demonstration purposes)\n",
    "X.iloc[0, 0] = None\n",
    "\n",
    "# Handle missing values using mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef9601",
   "metadata": {},
   "source": [
    "\n",
    "## Module 3: Feature Engineering and Selection for Enhanced Predictive Performance\n",
    "\n",
    "This module demonstrates feature engineering, selection, and dimensionality reduction using an example dataset.\n",
    "\n",
    "### Starter Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fc1d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load example dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(mutual_info_classif, k=2)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_selected)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8010e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
