{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> __Johns Hopkins University__</h3>\n",
    "## <h3 align=\"center\">__Whiting School of Engineering__</h3>\n",
    "## <h3 align=\"center\">__Engineering for Professionals__</h3>\n",
    "## <h3 align=\"center\">__685.701 Data Science: Modeling and Analytics__</h3>\n",
    "## <h3 align=\"center\">__Homework 4__</h3>\n",
    "## <h3 align=\"center\">__Assigned at the start of Module 10__</h3>\n",
    "## <h3 align=\"center\">__Due at the end of Module 12__</h3><br>\n",
    "## <h3 align=\"center\">__Total Points 100/100__</h3>\n",
    "Class, below is a standard set of instructions for each HW. <br><br>\n",
    "Students are allowed to work together on HW problem. Each student is required to write up their solutions individually for all problems in their respective submission. The goal is to advance your HW solutions beyond standard answers by helping each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __1. Load the Dataset__<br>\n",
    "16 Points Total<br><br>\n",
    "\n",
    "First, get the *Alice in Wonderland* dataset from the [Alice in Wonderland QA dataset](https://huggingface.co/datasets/dkasinets/alice_in_wonderland_qa), which contains questions and answers.\n",
    "\n",
    "You can access it using the Hugging Face `datasets` library:\n",
    "\n",
    "Hint:\n",
    "- `from datasets import load_dataset`\n",
    "- `dataset = load_dataset(\"dkasinets/alice_in_wonderland_qa\")`\n",
    "\n",
    "Then, filter for QA pairs where the summary title contains “Alice”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dkasinets/alice_in_wonderland_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which character sings 'Twas Brillig'?</td>\n",
       "      <td>The poem 'Jabberwocky' begins with the line ''...</td>\n",
       "      <td>No character sings it, but the poem 'Jabberwoc...</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What condiment did the Mad Hatter think was ri...</td>\n",
       "      <td>At the tea party, the Hatter inspects the Whit...</td>\n",
       "      <td>Mustard</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Alice's cat's name?</td>\n",
       "      <td>Alice often talks about her cat Dinah in the b...</td>\n",
       "      <td>Dinah</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the lizard with the ladder?</td>\n",
       "      <td>Bill the Lizard is called in by the White Rabb...</td>\n",
       "      <td>Bill</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the name that the White Rabbit called...</td>\n",
       "      <td>When Alice enters the White Rabbit's house, he...</td>\n",
       "      <td>Mary Anne</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Why does Alice shrink?</td>\n",
       "      <td>Alice drinks from a bottle labeled 'Drink Me' ...</td>\n",
       "      <td>Because she drank from a bottle labeled 'Drink...</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>What is the Queen's full name?</td>\n",
       "      <td>In Lewis Carroll's original book, the Queen is...</td>\n",
       "      <td>Iracebeth of Crims</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>What game does Alice play?</td>\n",
       "      <td>Alice plays a chaotic game of croquet with the...</td>\n",
       "      <td>Croquet</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Who wrote Alice's Adventures in Wonderland?</td>\n",
       "      <td>'Alice's Adventures in Wonderland' was written...</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Who played the Mad Hatter in Tim Burton's film...</td>\n",
       "      <td>In the 2010 film 'Alice in Wonderland' directe...</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                Which character sings 'Twas Brillig'?   \n",
       "1    What condiment did the Mad Hatter think was ri...   \n",
       "2                          What is Alice's cat's name?   \n",
       "3      What is the name of the lizard with the ladder?   \n",
       "4    What was the name that the White Rabbit called...   \n",
       "..                                                 ...   \n",
       "124                             Why does Alice shrink?   \n",
       "125                     What is the Queen's full name?   \n",
       "126                         What game does Alice play?   \n",
       "127        Who wrote Alice's Adventures in Wonderland?   \n",
       "128  Who played the Mad Hatter in Tim Burton's film...   \n",
       "\n",
       "                                               context  \\\n",
       "0    The poem 'Jabberwocky' begins with the line ''...   \n",
       "1    At the tea party, the Hatter inspects the Whit...   \n",
       "2    Alice often talks about her cat Dinah in the b...   \n",
       "3    Bill the Lizard is called in by the White Rabb...   \n",
       "4    When Alice enters the White Rabbit's house, he...   \n",
       "..                                                 ...   \n",
       "124  Alice drinks from a bottle labeled 'Drink Me' ...   \n",
       "125  In Lewis Carroll's original book, the Queen is...   \n",
       "126  Alice plays a chaotic game of croquet with the...   \n",
       "127  'Alice's Adventures in Wonderland' was written...   \n",
       "128  In the 2010 film 'Alice in Wonderland' directe...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    No character sings it, but the poem 'Jabberwoc...   \n",
       "1                                              Mustard   \n",
       "2                                                Dinah   \n",
       "3                                                 Bill   \n",
       "4                                            Mary Anne   \n",
       "..                                                 ...   \n",
       "124  Because she drank from a bottle labeled 'Drink...   \n",
       "125                                 Iracebeth of Crims   \n",
       "126                                            Croquet   \n",
       "127                                      Lewis Carroll   \n",
       "128                                        Johnny Depp   \n",
       "\n",
       "                                                source  \n",
       "0    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "1    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "2    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "3    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "4    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "..                                                 ...  \n",
       "124                         AI generated by ChatGPT-4o  \n",
       "125                         AI generated by ChatGPT-4o  \n",
       "126                         AI generated by ChatGPT-4o  \n",
       "127                         AI generated by ChatGPT-4o  \n",
       "128                         AI generated by ChatGPT-4o  \n",
       "\n",
       "[129 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_df = pd.DataFrame(dataset['train'])\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which character sings 'Twas Brillig'?</td>\n",
       "      <td>The poem 'Jabberwocky' begins with the line ''...</td>\n",
       "      <td>No character sings it, but the poem 'Jabberwoc...</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Alice's cat's name?</td>\n",
       "      <td>Alice often talks about her cat Dinah in the b...</td>\n",
       "      <td>Dinah</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the lizard with the ladder?</td>\n",
       "      <td>Bill the Lizard is called in by the White Rabb...</td>\n",
       "      <td>Bill</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the name that the White Rabbit called...</td>\n",
       "      <td>When Alice enters the White Rabbit's house, he...</td>\n",
       "      <td>Mary Anne</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What does the White Rabbit need when Alice gro...</td>\n",
       "      <td>The White Rabbit asks for 'a lizard with a lad...</td>\n",
       "      <td>A lizard with a ladder</td>\n",
       "      <td>https://www.funtrivia.com/en/Movies/Alice-in-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Why is the little fish called a 'whiting', acc...</td>\n",
       "      <td>The Gryphon says it's called a whiting because...</td>\n",
       "      <td>Because it cleans boots and shoes in the ocean.</td>\n",
       "      <td>https://astreaacademytrust.org/wp-content/uplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Why does Alice shrink?</td>\n",
       "      <td>Alice drinks from a bottle labeled 'Drink Me' ...</td>\n",
       "      <td>Because she drank from a bottle labeled 'Drink...</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>What game does Alice play?</td>\n",
       "      <td>Alice plays a chaotic game of croquet with the...</td>\n",
       "      <td>Croquet</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Who wrote Alice's Adventures in Wonderland?</td>\n",
       "      <td>'Alice's Adventures in Wonderland' was written...</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Who played the Mad Hatter in Tim Burton's film...</td>\n",
       "      <td>In the 2010 film 'Alice in Wonderland' directe...</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>AI generated by ChatGPT-4o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                Which character sings 'Twas Brillig'?   \n",
       "2                          What is Alice's cat's name?   \n",
       "3      What is the name of the lizard with the ladder?   \n",
       "4    What was the name that the White Rabbit called...   \n",
       "5    What does the White Rabbit need when Alice gro...   \n",
       "..                                                 ...   \n",
       "121  Why is the little fish called a 'whiting', acc...   \n",
       "124                             Why does Alice shrink?   \n",
       "126                         What game does Alice play?   \n",
       "127        Who wrote Alice's Adventures in Wonderland?   \n",
       "128  Who played the Mad Hatter in Tim Burton's film...   \n",
       "\n",
       "                                               context  \\\n",
       "0    The poem 'Jabberwocky' begins with the line ''...   \n",
       "2    Alice often talks about her cat Dinah in the b...   \n",
       "3    Bill the Lizard is called in by the White Rabb...   \n",
       "4    When Alice enters the White Rabbit's house, he...   \n",
       "5    The White Rabbit asks for 'a lizard with a lad...   \n",
       "..                                                 ...   \n",
       "121  The Gryphon says it's called a whiting because...   \n",
       "124  Alice drinks from a bottle labeled 'Drink Me' ...   \n",
       "126  Alice plays a chaotic game of croquet with the...   \n",
       "127  'Alice's Adventures in Wonderland' was written...   \n",
       "128  In the 2010 film 'Alice in Wonderland' directe...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    No character sings it, but the poem 'Jabberwoc...   \n",
       "2                                                Dinah   \n",
       "3                                                 Bill   \n",
       "4                                            Mary Anne   \n",
       "5                               A lizard with a ladder   \n",
       "..                                                 ...   \n",
       "121    Because it cleans boots and shoes in the ocean.   \n",
       "124  Because she drank from a bottle labeled 'Drink...   \n",
       "126                                            Croquet   \n",
       "127                                      Lewis Carroll   \n",
       "128                                        Johnny Depp   \n",
       "\n",
       "                                                source  \n",
       "0    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "2    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "3    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "4    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "5    https://www.funtrivia.com/en/Movies/Alice-in-W...  \n",
       "..                                                 ...  \n",
       "121  https://astreaacademytrust.org/wp-content/uplo...  \n",
       "124                         AI generated by ChatGPT-4o  \n",
       "126                         AI generated by ChatGPT-4o  \n",
       "127                         AI generated by ChatGPT-4o  \n",
       "128                         AI generated by ChatGPT-4o  \n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df_filtered = dataset_df[dataset_df[\"context\"].str.contains(\"Alice\")]\n",
    "dataset_df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __2. Load a Small LLM from HuggingFace__<br>\n",
    "16 Points Total<br><br>\n",
    "\n",
    "Check out the <a href=\"https://huggingface.co\" target=\"_blank\"> HuggingFace website </a> to see models, datasets, and a community working on Large Language models, foundation models, and multi-modal models. These models are uploaded by large organizations and individuals such as researchers, doctoral students, etc. \n",
    "\n",
    "Choose a model suitable for question-answering, summarization, or sentiment analysis.\n",
    "Use a small transformer model like `google/flan-t5-base` or `google/flan-t5-small` for this task. \n",
    "\n",
    "Note that,\n",
    "- The entire solution can run on a notebook with a small GPU quickly (a CPU would a few times slower but still not too long)\n",
    "- The number of \"Most downloads\" and/or \"Trending\" will give a pointer to which model to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version = 2.8.0+cu126\n",
      "cude available = True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f'torch version = {torch.__version__}')\n",
    "print(f'cude available = {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version = 4.57.1\n"
     ]
    }
   ],
   "source": [
    "## Provided this Cell  ##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "import transformers\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n",
    "# from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "# filter warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "print(f'transformers version = {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __3. Trivia Questions__<br>\n",
    "16 Points Total<br><br>\n",
    "\n",
    "Let's first test the model on trivia questions unrelated to the novel to check general performance.\n",
    "\n",
    "Baseline Questions:\n",
    "- \"Which American city is the Statue of Liberty located in?\"\n",
    "- \"What is the capital of France?\"\n",
    "- \"Who is the president of the United States?\"\n",
    "- \"What is the most probable word coming after 'Alice in'?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['philadelphia', 'london', 'jimmy carter', 'adolescent']\n"
     ]
    }
   ],
   "source": [
    "# List of baseline trivia questions\n",
    "model_inputs = [\n",
    "    \"Which American city is the Statue of Liberty located in?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who is the president of the United States?\",\n",
    "    \"What is the most probable word coming after 'Alice in'?\"\n",
    "]\n",
    "inputs = tokenizer(model_inputs, return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __4. Novel-Based Questions (Before Fine-Tuning)__<br>\n",
    "16 Points Total<br><br>\n",
    "\n",
    "Now, test the model's performance on questions about Alice in Wonderland, before fine-tuning.\n",
    "\n",
    "Novel Questions:\n",
    "- \"What is the White Rabbit's catchphrase?\"\n",
    "- \"Why does Alice shrink?\"\n",
    "- \"What is the Queen's full name?\"\n",
    "- \"What game does Alice play?\"\n",
    "- \"Who wrote Alice's Adventures in Wonderland?\"\n",
    "- \"Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love you', 'she is pregnant', 'anne of wales', 'chess', 'edward wilson', 'eddie mccartney']\n"
     ]
    }
   ],
   "source": [
    "# Novel-related questions\n",
    "# List of baseline trivia questions\n",
    "model_inputs = [\n",
    "    \"What is the White Rabbit's catchphrase?\",\n",
    "    \"Why does Alice shrink?\",\n",
    "    \"What is the Queen's full name?\",\n",
    "    \"What game does Alice play?\",\n",
    "    \"Who wrote Alice's Adventures in Wonderland?\",\n",
    "    \"Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\"\n",
    "]\n",
    "inputs = tokenizer(model_inputs, return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __5. Fine-Tune the Model on the Alice in Wonderland__<br>\n",
    "20 Points Total<br><br>\n",
    "\n",
    "Use the HuggingFace's `Trainer` and `Dataset` APIs to fine-tune the model on *Alice in Wonderland*-related questions from the <a href=\"https://huggingface.co/datasets/dkasinets/alice_in_wonderland_qa\" target=\"_blank\">Alice in Wonderland QA dataset</a> (or any other relevant datasets).\n",
    "\n",
    "Alternatively, find a way to pass additional context into the model to improve Question Answering. \n",
    "\n",
    "Explain your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune FLAN-T5 on the Alice in Wonderland dataset, the key step is to treat QA as a text-to-text problem. Instead of feeding only the question, you concatenate the question and its context into a single input string such as: \"question: … context: …\". T5 was pretrained in this format, so providing explicit context allows it to learn which parts of the passage contain the answer and reduces hallucination. During preprocessing, the inputs are tokenized normally while the answer text becomes the target sequence, with padding tokens masked using -100 so they don't contribute to the loss. The HuggingFace Trainer class then handles batching, optimization, and evaluation. With a modest learning rate and properly aligned labels, the model can learn to map a combined question-and-context input into a concise answer, resulting in a cleaner and more accurate QA system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ff34c7e7dc45a5a4f12fe41771ef77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [165/165 36:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34.681300</td>\n",
       "      <td>21.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>17.184600</td>\n",
       "      <td>6.738342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.258100</td>\n",
       "      <td>4.485875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.590700</td>\n",
       "      <td>4.078912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.259100</td>\n",
       "      <td>3.940339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('flan-t5-alice-qa-model\\\\tokenizer_config.json',\n",
       " 'flan-t5-alice-qa-model\\\\special_tokens_map.json',\n",
       " 'flan-t5-alice-qa-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "def preprocess(batch):\n",
    "\n",
    "    # Construct the full input prompt\n",
    "    inputs = [\n",
    "        f\"answer the question based on the context.\\nquestion: {q}\\ncontext: {c}\"\n",
    "        for q, c in zip(batch[\"question\"], batch[\"context\"])\n",
    "    ]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    # Tokenize labels (just the answer text)\n",
    "    labels = tokenizer(\n",
    "        batch[\"answer\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    # Replace pad tokens with -100\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    labels = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
    "        for label in labels\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"flan-t5-alice-qa\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    logging_steps=20,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"train\"],  # ok for testing\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"flan-t5-alice-qa-model\")\n",
    "tokenizer.save_pretrained(\"flan-t5-alice-qa-model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __6. Ask the Same Questions Again (After Fine-Tuning or Better Context)__<br>\n",
    "16 Points Total<br><br>\n",
    "\n",
    "Once you've updated the model's knowledge (via fine-tuning or embedding additional context), re-run the same questions from before.\n",
    "\n",
    "Compare the answers. Did they improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fine-tuning the model using question + context pairs, the answers generally become more grounded in the actual text because the model no longer tries to guess from prior knowledge alone. Instead, it learns to extract information directly from the provided passages. When you re-run the original questions, any improvement will show up as answers that are more specific, text-accurate, and less hallucinated. If the answers didn’t improve much, it usually means the training dataset is too small, the learning rate was too high, or the model wasn't given enough contextual information during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the White Rabbit's catchphrase?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can't believe i can'\n",
      "Question: Why does Alice shrink?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:she is pregnant with a baby\n",
      "Question: What is the Queen's full name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:elizabeth ii\n",
      "Question: What game does Alice play?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:game of chess\n",
      "Question: Who wrote Alice's Adventures in Wonderland?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:edward wilson\n",
      "Question: Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\n",
      "Answer:michael jackson\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"./flan-t5-alice-qa-model\",\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")\n",
    "\n",
    "model_inputs = [\n",
    "    \"What is the White Rabbit's catchphrase?\",\n",
    "    \"Why does Alice shrink?\",\n",
    "    \"What is the Queen's full name?\",\n",
    "    \"What game does Alice play?\",\n",
    "    \"Who wrote Alice's Adventures in Wonderland?\",\n",
    "    \"Who played the Mad Hatter in Tim Burton's film version of Alice's Adventures in Wonderland?\"\n",
    "]\n",
    "\n",
    "for question in model_inputs:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer:{pipe(question, max_length=64)[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __7. Go Beyond: Bonus Challenge__<br>\n",
    "20 Bonus Points Total<br><br>\n",
    "\n",
    "- Fine-tune your model on multiple classic books from <a href=\"https://huggingface.co/datasets/deepmind/narrativeqa\" target=\"_blank\">NarrativeQA dataset</a>, and create a general-purpose literary QA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Execution Comment\n",
    "\n",
    "Fine-tuning on a dataset of this size would take approximately a full day on my current hardware. While the code is fully functional and capable of fine-tuning on the new dataset, I did not run it to completion due to time constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978813981db743c3944f5eaadcff7707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8781729d87554fc9ad1edb6463590978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c5beee2dfd4652bc07978b59ed21fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29814e95e9f54c70bdf8be85aa78ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10557 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"deepmind/narrativeqa\")\n",
    "\n",
    "def preprocess(batch):\n",
    "\n",
    "    # Construct the full input prompt\n",
    "    inputs = [\n",
    "        f\"answer the question.\\nquestion: {q['text']}\"\n",
    "        for q in batch[\"question\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    # Tokenize labels (just the answer text)\n",
    "    answers = [a[0][\"text\"] for a in batch[\"answers\"]]\n",
    "    labels = tokenizer(\n",
    "        answers,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    # Replace pad tokens with -100\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    labels = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
    "        for label in labels\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=ds[\"train\"].column_names\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"flan-t5-alice-qa\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    logging_steps=20,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],  # ok for testing\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# trainer.train()\n",
    "# model.save_pretrained(\"flan-t5-narrative-model\")\n",
    "# tokenizer.save_pretrained(\"flan-t5-narrative-model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Natural Language Processing with Python. NLTK Project, https://www.nltk.org/book/.\n",
    "- Hugging Face. Hugging Face. https://huggingface.co.\n",
    "- Hugging Face. google/flan-t5-small. https://huggingface.co/google/flan-t5-small.\n",
    "- Hugging Face Datasets. deepmind/narrativeqa. https://huggingface.co/datasets/deepmind/narrativeqa.\n",
    "- Project Gutenberg. https://www.gutenberg.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
