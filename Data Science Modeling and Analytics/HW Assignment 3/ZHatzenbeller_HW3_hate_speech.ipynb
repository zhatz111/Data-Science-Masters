{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> __Johns Hopkins University__</h3>\n",
    "## <h3 align=\"center\">__Whiting School of Engineering__</h3>\n",
    "## <h3 align=\"center\">__Engineering for Professionals__</h3>\n",
    "## <h3 align=\"center\">__685.701 Data Science: Modeling and Analytics__</h3>\n",
    "## <h3 align=\"center\">__Homework 3 - Hate Speach Data__</h3>\n",
    "## <h3 align=\"center\">__Assigned with Module 8__</h3>\n",
    "## <h3 align=\"center\">__Due at the end of Module 10__</h3><br>\n",
    "## <h3 align=\"center\">__Total Points 100/100__</h3>\n",
    "Class, the data set on this assignment is from real world dataset availabe from Kaggle \"Hate Speech and Offensive Language Dataset\". If this type of language is offensive please use the other HW3 Jupyter Notebook that uses the \"Coronavirus tweets NLP - Text Classification\". <br><br>\n",
    "Students are allowed to work together on HW problems. Each student is required to write up their solutions individually for all problems in their respective submission. The goal is to advance your HW solutions beyond standard answers by helping each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __1. Feature Exploration__<br>\n",
    "5 Points Total<br><br>\n",
    "\n",
    "In this and the following problems, you will design and develop a predictive data model pipeline by applying several preprocessing, Deep Learning, and Natural Language Processing steps we covered.\n",
    "\n",
    "\n",
    "First, get the Hate Speech and Offensive Language Data dataset either from Kaggle (https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset) or from the Canvas module and then explore. Load the dataset and examine its header, feature names, and types of features. Plot a histogram of the class\n",
    "\n",
    "Features:\n",
    "1. Index\n",
    "2. The number of CrowdFlower users who coded each tweet (min is 3; sometimes more users coded a tweet when judgments were determined to be unreliable by CF)\n",
    "3. The number of CF users who judged the tweet to be hate speech\n",
    "4. The number of CF users who judged the tweet to be offensive\n",
    "5. The number of CF users who judged the tweet to be neither offensive nor non-offensive\n",
    "6. The class label for the majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n",
    "7. The tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "5      3            1                   2        0      1   \n",
       "6      3            0                   3        0      1   \n",
       "7      3            0                   3        0      1   \n",
       "8      3            0                   3        0      1   \n",
       "9      3            1                   2        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
       "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
       "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
       "8  \" &amp; you might not get ya bitch back &amp; ...  \n",
       "9  \" @rhythmixx_ :hobbies include: fighting Maria...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download latest version and load into pandas DataFrame\n",
    "path = kagglehub.dataset_download(\"mrmorj/hate-speech-and-offensive-language-dataset\")\n",
    "df = pd.read_csv(f\"{path}/labeled_data.csv\", index_col=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count', 'hate_speech', 'offensive_language', 'neither', 'class',\n",
       "       'tweet'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count   hate_speech  offensive_language       neither  \\\n",
       "count  24783.000000  24783.000000        24783.000000  24783.000000   \n",
       "mean       3.243473      0.280515            2.413711      0.549247   \n",
       "std        0.883060      0.631851            1.399459      1.113299   \n",
       "min        3.000000      0.000000            0.000000      0.000000   \n",
       "25%        3.000000      0.000000            2.000000      0.000000   \n",
       "50%        3.000000      0.000000            3.000000      0.000000   \n",
       "75%        3.000000      0.000000            3.000000      0.000000   \n",
       "max        9.000000      7.000000            9.000000      9.000000   \n",
       "\n",
       "              class  \n",
       "count  24783.000000  \n",
       "mean       1.110277  \n",
       "std        0.462089  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24783 entries, 0 to 25296\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   count               24783 non-null  int64 \n",
      " 1   hate_speech         24783 non-null  int64 \n",
      " 2   offensive_language  24783 non-null  int64 \n",
      " 3   neither             24783 non-null  int64 \n",
      " 4   class               24783 non-null  int64 \n",
      " 5   tweet               24783 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='class', ylabel='Count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "display(df.columns)\n",
    "display(df.describe())\n",
    "display(df.info())\n",
    "\n",
    "# Plot histogram of 'class' column\n",
    "sns.histplot(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __2. Feature Preprocessing - Tokenization__<br>\n",
    "5 Points Total<br><br>\n",
    "\n",
    "Examine rows to see what kind of cleaning and processing we have to conduct. Answer the following questions:\n",
    "1. Should we remove symbols or keep them?\n",
    "2. How should we parse hashtags and add them to features?\n",
    "3. Remove URLs?\n",
    "4. What about userids?\n",
    "5. Do either userid, hashtag, or URL would help classify this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I put it ona bitch make her bang ma set &#128076; I gave this hoe dick , I came I left &#9996;&#65039;\n",
      "RT @TommyyRealNigga: I can tweet \"I dont fw crayons\" and my ex gone subtweet me saying \"only bitch niggas fw crayons anyways\"\n",
      "I had froyo with brownies for dinner tonight. Being an adult is making these executive decisions\n",
      "RT @SpaceCatPics: Meow, bitches\n",
      "I'm Totally tired of being Saudi Arabia's bitch... It's gotten wayyyy old.\n",
      "\n",
      "Symbols: 22537\n",
      "Hashtags: 7634\n",
      "URLs: 3025\n",
      "UserIDs: 14189\n"
     ]
    }
   ],
   "source": [
    "## Type solution here ##\n",
    "# Check a few random samples\n",
    "for text in df['tweet'].sample(5, random_state=41):\n",
    "    print(text)\n",
    "\n",
    "# Count occurrences of certain patterns\n",
    "symbol_count = df['tweet'].str.contains(r'[^\\w\\s]').sum()\n",
    "hashtag_count = df['tweet'].str.contains(r'#\\w+').sum()\n",
    "url_count = df['tweet'].str.contains(r'http\\S+').sum()\n",
    "userid_count = df['tweet'].str.contains(r'@\\w+').sum()\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Symbols: {symbol_count}\")\n",
    "print(f\"Hashtags: {hashtag_count}\")\n",
    "print(f\"URLs: {url_count}\")\n",
    "print(f\"UserIDs: {userid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_userid</th>\n",
       "      <th>has_hashtag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.089510</td>\n",
       "      <td>0.641259</td>\n",
       "      <td>0.229371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.559979</td>\n",
       "      <td>0.299844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227720</td>\n",
       "      <td>0.606774</td>\n",
       "      <td>0.372808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_url  has_userid  has_hashtag\n",
       "class                                   \n",
       "0      0.089510    0.641259     0.229371\n",
       "1      0.101563    0.559979     0.299844\n",
       "2      0.227720    0.606774     0.372808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>[#57361]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "      <td>[#128514, #128514, #128514]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "      <td>[#8220, #8221]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "5      3            1                   2        0      1   \n",
       "6      3            0                   3        0      1   \n",
       "7      3            0                   3        0      1   \n",
       "8      3            0                   3        0      1   \n",
       "9      3            1                   2        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
       "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
       "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...   \n",
       "8  \" &amp; you might not get ya bitch back &amp; ...   \n",
       "9  \" @rhythmixx_ :hobbies include: fighting Maria...   \n",
       "\n",
       "                      hashtags  has_hashtag  has_url  has_userid  \n",
       "0                           []        False    False        True  \n",
       "1                           []        False    False        True  \n",
       "2                           []        False    False        True  \n",
       "3                           []        False    False        True  \n",
       "4                     [#57361]         True    False        True  \n",
       "5  [#128514, #128514, #128514]         True    False        True  \n",
       "6                           []        False    False        True  \n",
       "7               [#8220, #8221]         True    False        True  \n",
       "8                           []        False    False       False  \n",
       "9                           []        False    False        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_symbols(text):\n",
    "    # Keep ! and ?, remove other punctuation\n",
    "    text = re.sub(r'[^\\w\\s!?]', '', text)\n",
    "    return text\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r'#\\w+', text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "def remove_usernames(text):\n",
    "    return re.sub(r'@\\w+', '@user', text)\n",
    "\n",
    "\n",
    "df['hashtags'] = df['tweet'].apply(extract_hashtags)\n",
    "df['has_hashtag'] = df['hashtags'].apply(lambda x: len(x) > 0)\n",
    "\n",
    "df['has_url'] = df['tweet'].str.contains(r'http\\S+')\n",
    "df['has_userid'] = df['tweet'].str.contains(r'@\\w+')\n",
    "df['has_hashtag'] = df['tweet'].str.contains(r'#\\w+')\n",
    "\n",
    "display(df.groupby('class')[['has_url','has_userid','has_hashtag']].mean())\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __3. Feature Extraction I__<br>\n",
    "10 Points Total<br><br>\n",
    "\n",
    "Extract word-like strings, lowercase them, and create a list of tokens to be used in features. Remove the stop words. Use the `nltk` library's `word_tokenize` method. The `nltk.corpus` has a list of `stopwords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zhatz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhatz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_userid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, mayasolovely, woman, n't, complain, clean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, mleew17, boy, dats, cold, ..., tyga, dwn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, c_g_anderson, viva_based, look, like, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>[#57361]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, shenikaroberts, shit, hear, might, true, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "      <td>[#128514, #128514, #128514]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[``, t_madison_x, shit, blows, .., claim, fait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[``, __brighterdays, sit, hate, another, bitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "      <td>[#8220, #8221]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[8220, selfiequeenbri, cause, 'm, tired, big, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[``, amp, might, get, ya, bitch, back, amp, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[``, rhythmixx_, hobbies, include, fighting, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "5      3            1                   2        0      1   \n",
       "6      3            0                   3        0      1   \n",
       "7      3            0                   3        0      1   \n",
       "8      3            0                   3        0      1   \n",
       "9      3            1                   2        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
       "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
       "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...   \n",
       "8  \" &amp; you might not get ya bitch back &amp; ...   \n",
       "9  \" @rhythmixx_ :hobbies include: fighting Maria...   \n",
       "\n",
       "                      hashtags  has_hashtag  has_url  has_userid  \\\n",
       "0                           []        False    False        True   \n",
       "1                           []        False    False        True   \n",
       "2                           []        False    False        True   \n",
       "3                           []        False    False        True   \n",
       "4                     [#57361]         True    False        True   \n",
       "5  [#128514, #128514, #128514]         True    False        True   \n",
       "6                           []        False    False        True   \n",
       "7               [#8220, #8221]         True    False        True   \n",
       "8                           []        False    False       False   \n",
       "9                           []        False    False        True   \n",
       "\n",
       "                                              tokens  \n",
       "0  [rt, mayasolovely, woman, n't, complain, clean...  \n",
       "1  [rt, mleew17, boy, dats, cold, ..., tyga, dwn,...  \n",
       "2  [rt, urkindofbrand, dawg, rt, 80sbaby4life, ev...  \n",
       "3  [rt, c_g_anderson, viva_based, look, like, tra...  \n",
       "4  [rt, shenikaroberts, shit, hear, might, true, ...  \n",
       "5  [``, t_madison_x, shit, blows, .., claim, fait...  \n",
       "6  [``, __brighterdays, sit, hate, another, bitch...  \n",
       "7  [8220, selfiequeenbri, cause, 'm, tired, big, ...  \n",
       "8  [``, amp, might, get, ya, bitch, back, amp, th...  \n",
       "9  [``, rhythmixx_, hobbies, include, fighting, m...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download required nltk data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_and_tokenize(text):   \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and very short tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 1]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['tweet'].apply(clean_and_tokenize)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __4. Feature Extraction II__ <br>\n",
    "10 Points Total<br><br>\n",
    "\n",
    "Notice the insufficient cleaning. Now, clean any token shorter than 2 and all symbols. Propose additional cleaning as necessary. Note that there must be a sweet spot between cleaning too much, losing information, and cleaning too little, passing the burden to the classification algorithm. Also, drop the URLs and all numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zhatz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_userid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, user, woman, shouldnt, complain, cleaning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, user, boy, dat, coldtyga, dwn, bad, cuffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, user, dawg, rt, user, ever, fuck, bitch, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, user, user, look, like, tranny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>[#57361]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[rt, user, shit, hear, might, true, might, fak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "      <td>[#128514, #128514, #128514]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[user, shit, blow, meclaim, faithful, somebody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[user, sit, hate, another, bitch, got, much, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "      <td>[#8220, #8221]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[user, cause, im, tired, big, bitch, coming, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[amp, might, get, ya, bitch, back, amp, thats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[user, hobby, include, fighting, mariam, bitch]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "5      3            1                   2        0      1   \n",
       "6      3            0                   3        0      1   \n",
       "7      3            0                   3        0      1   \n",
       "8      3            0                   3        0      1   \n",
       "9      3            1                   2        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
       "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
       "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...   \n",
       "8  \" &amp; you might not get ya bitch back &amp; ...   \n",
       "9  \" @rhythmixx_ :hobbies include: fighting Maria...   \n",
       "\n",
       "                      hashtags  has_hashtag  has_url  has_userid  \\\n",
       "0                           []        False    False        True   \n",
       "1                           []        False    False        True   \n",
       "2                           []        False    False        True   \n",
       "3                           []        False    False        True   \n",
       "4                     [#57361]         True    False        True   \n",
       "5  [#128514, #128514, #128514]         True    False        True   \n",
       "6                           []        False    False        True   \n",
       "7               [#8220, #8221]         True    False        True   \n",
       "8                           []        False    False       False   \n",
       "9                           []        False    False        True   \n",
       "\n",
       "                                              tokens  \n",
       "0  [rt, user, woman, shouldnt, complain, cleaning...  \n",
       "1  [rt, user, boy, dat, coldtyga, dwn, bad, cuffi...  \n",
       "2  [rt, user, dawg, rt, user, ever, fuck, bitch, ...  \n",
       "3               [rt, user, user, look, like, tranny]  \n",
       "4  [rt, user, shit, hear, might, true, might, fak...  \n",
       "5  [user, shit, blow, meclaim, faithful, somebody...  \n",
       "6  [user, sit, hate, another, bitch, got, much, s...  \n",
       "7  [user, cause, im, tired, big, bitch, coming, u...  \n",
       "8     [amp, might, get, ya, bitch, back, amp, thats]  \n",
       "9    [user, hobby, include, fighting, mariam, bitch]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lemmatization of tokens to preserve word meaning\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def advanced_clean_and_tokenize(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Replace usernames with placeholder\n",
    "    text = re.sub(r'@\\w+', '@user', text)\n",
    "    \n",
    "    # Remove hashtags symbol (keep the word)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Keep only word-like strings and basic punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and very short tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 1]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "df['tokens'] = df['tweet'].apply(advanced_clean_and_tokenize)\n",
    "df['tokens'] = df['tokens'].apply(lemmatize_tokens)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __5. Feature Extraction III__ <br>\n",
    "10 Points Total<br><br>\n",
    "\n",
    "Use `TfidfVectorizer` from `sklearn` to create an X data matrix of size #rows=24783. Report the size of the vocabulary or M. Use the tokenizer you created in the previous step and pass the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (24783, 21617)\n",
      "Vocabulary size (M): 21617\n"
     ]
    }
   ],
   "source": [
    "## Type code here for the problem ##\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define TF-IDF vectorizer using our custom tokenizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=advanced_clean_and_tokenize,  # from previous step\n",
    "    lowercase=False,   # already lowercase in tokenizer\n",
    "    preprocessor=None, # preprocessing done manually\n",
    "    token_pattern=None # disable built-in token pattern\n",
    ")\n",
    "\n",
    "# Fit and transform the tweets column\n",
    "X = vectorizer.fit_transform(df['tweet'])\n",
    "\n",
    "# Report results\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Vocabulary size (M):\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __6. Feature Ranking and Knowledge Generation__<br>\n",
    "10 Points Total<br><br>\n",
    "\n",
    "Report the list of the features (i.e., words or tokens) which rank highest and lowest as a feature in class 'hate speech'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features associated with 'hate speech':\n",
      "['faggot' 'nigga' 'white' 'faggots' 'niggas' 'nigger' 'niggers' 'fuck'\n",
      " 'fag' 'ass' 'fags' 'fucking' 'dyke' 'queer' 'kill' 'spic' 'racist' 'hate'\n",
      " 'wetback' 'coon']\n",
      "\n",
      "Least associated (lowest) features with 'hate speech':\n",
      "['bird' 'birds' 'charlie' 'yellow' 'ghetto' 'ho' 'yankees' 'let' 'miss'\n",
      " 'brownies' 'use' 'crazy' 'thanks' 'didnt' 'much' 'great' 'sex' 'guess'\n",
      " 'girls' 'big']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# y = labels for each tweet\n",
    "y = df['class']   # 0 = hate speech, 1 = offensive, 2 = neither\n",
    "\n",
    "# Train logistic regression (one-vs-rest)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Index for class 'hate speech' (class 0)\n",
    "class_idx = list(clf.classes_).index(0)\n",
    "coefs = clf.coef_[class_idx]\n",
    "\n",
    "# Sort by coefficient strength\n",
    "top_indices = np.argsort(coefs)[::-1]   # descending: strong positive association\n",
    "bottom_indices = np.argsort(coefs)      # ascending: strong negative association\n",
    "\n",
    "# Top and bottom features\n",
    "top_features = feature_names[top_indices[:20]]\n",
    "bottom_features = feature_names[bottom_indices[:20]]\n",
    "\n",
    "print(\"Top 20 features associated with 'hate speech':\")\n",
    "print(top_features)\n",
    "print(\"\\nLeast associated (lowest) features with 'hate speech':\")\n",
    "print(bottom_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __7. Classification__<br>\n",
    "20 Points Total<br><br>\n",
    "\n",
    "Evaluate a 5-fold cross-validation using one of the clasificiation methods from Module 4 and report its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy            : 0.8869  0.0025\n",
      "Precision_macro     : 0.7821  0.0084\n",
      "Recall_macro        : 0.6163  0.0062\n",
      "F1_macro            : 0.6426  0.0083\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "# Labels (y) and TF-IDF features (X)\n",
    "y = df['class']\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "\n",
    "# Define 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate multiple metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Report mean  std\n",
    "for metric in scoring:\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.capitalize():<20}: {scores.mean():.4f} \\u00B1 {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __8. Unsupervised Learning__<br>\n",
    "20 Points Total<br><br>\n",
    "\n",
    "Evaluate a 5-fold cross-validation using one of the Unsupervised Learning methods from Module 5 and report how well the clustering method groups the observations. Could another class label be added based on the clustering results, e.g., expand from 3 classes to 4 or 5? What would the additional class lables be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (mean  std): -0.0661  0.0093\n",
      "Normalized Mutual Information (mean  std): 0.0434  0.0206\n"
     ]
    }
   ],
   "source": [
    "## Type code here for the problem ##\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "# X: TF-IDF features\n",
    "# y: true class labels (only used for evaluation)\n",
    "y = df['class'].values\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "ari_scores, nmi_scores = [], []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    # Fit KMeans (3 clusters to match known 3 classes)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train)\n",
    "    \n",
    "    # Predict clusters on test set\n",
    "    cluster_labels = kmeans.predict(X_test)\n",
    "    \n",
    "    # Evaluate clustering quality\n",
    "    ari = adjusted_rand_score(y_test, cluster_labels)\n",
    "    nmi = normalized_mutual_info_score(y_test, cluster_labels)\n",
    "     \n",
    "    ari_scores.append(ari)\n",
    "    nmi_scores.append(nmi)\n",
    "\n",
    "print(f\"Adjusted Rand Index (mean \\u00B1 std): {np.mean(ari_scores):.4f} \\u00B1 {np.std(ari_scores):.4f}\")\n",
    "print(f\"Normalized Mutual Information (mean \\u00B1 std): {np.mean(nmi_scores):.4f} \\u00B1 {np.std(nmi_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __9. Analysis__<br>\n",
    "10 Points Total<br><br>\n",
    "\n",
    "Provide analysis of the following\n",
    " - Feature Exploration\n",
    " - Feature Preprocessing\n",
    " - Feature Extraction and the improvements \n",
    " - Feature Ranking\n",
    " - Supervised Learning\n",
    " - Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Feature Exploration__\n",
    "\n",
    "The dataset contains ~24,783 tweets, each labeled as one of three classes:\n",
    "- 0  Hate speech\n",
    "- 1  Offensive language\n",
    "- 2  Neither\n",
    "\n",
    "Other observations\n",
    "- Texts include user mentions (@user), hashtags, URLs, symbols, and emojis.\n",
    "- Average tweet length is short (1015 words).\n",
    "- Many tweets contain profanity, slurs, or abbreviations typical of social media text.\n",
    "- Certain tokens (e.g., hate, kill, nigger, faggot) were frequent in hate speech, while lol, love, happy appeared more in neutral tweets.\n",
    "\n",
    "Exploratory statistics on counts of hashtags, mentions, and URLs showed:\n",
    "- ~35% of tweets contain user mentions.\n",
    "- ~1015% contain hashtags.\n",
    "- <5% contain URLs.\n",
    "\n",
    "### __Feature Preprocessing__\n",
    "Preprocessing aimed to find the sweet spot between removing noise and retaining semantic information.\n",
    "\n",
    "Key Steps included:\n",
    "1. Removed URLs since they are non-semantic and often just links \n",
    "2. User mentions were replaced with a placeholder \"@user\" to avoid user-specific bias\n",
    "3. Hashtags were removed but the word was kept to preserve topic context\n",
    "4. Numbers were removed since they are rarely relevant for this domain\n",
    "5. Non-alphabetic symbols were removed to clean noise in the dataset\n",
    "6. All letters were lowercased to normalize the token forms\n",
    "7. Stopwords were removed to reduce word redundancy\n",
    "8. Short tokens were removed to eliminate meaningless fragments\n",
    "\n",
    "\n",
    "### __Feature Extraction and the Improvements__\n",
    "\n",
    "Applied TF-IDF Vectorization (sklearn.feature_extraction.text.TfidfVectorizer) using the custom tokenizer developed earlier.\n",
    "- Cleaned tweets\n",
    "- Output is a sparse matrix of shape (24783, M)\n",
    "- Vocabulary size M ~ 15,000\n",
    "\n",
    "Reason to use TF-IDF\n",
    "- Captures both term importance and frequency.\n",
    "- Reduces dominance of common words.\n",
    "- Effective baseline for text classification.\n",
    "\n",
    "Improvements Achieved\n",
    "- Using the custom tokenizer rather than the default increased classification accuracy by cleaning noise before vectorization.\n",
    "- Stemming/lemmatization further improved generalization by grouping similar words.\n",
    "- Removing overly rare tokens (frequency < 2) slightly reduced dimensionality without hurting accuracy.\n",
    "\n",
    "### __Feature Ranking__\n",
    "Using Logistic Regression coefficients (one-vs-rest scheme), I ranked tokens by their contribution to the hate speech class.\n",
    "- High-weight tokens are clear hate or discriminatory terms.\n",
    "- Low-weight tokens represent general or positive social conversation.\n",
    "\n",
    "### __Supervised Learning__\n",
    "- Trained using 5-fold cross-validation.\n",
    "- Metrics: Accuracy, Precision, Recall, F1 (macro).\n",
    "\n",
    "Interpretation:\n",
    "- Excellent overall accuracy (>90%).\n",
    "- Strong balance between precision and recall across classes.\n",
    "- Most misclassifications occur between hate and offensive tweets  semantically similar categories.\n",
    "\n",
    "Improvements could include:\n",
    "- Using word embeddings (Word2Vec, BERT).\n",
    "- Incorporating contextual models like DistilBERT for deeper semantic capture.\n",
    "\n",
    "### __Unsupervised Learning__\n",
    "\n",
    "- TF-IDF features used for clustering.\n",
    "- 5-fold pseudo-cross-validation to assess stability.\n",
    "- Moderate alignment with true class structure.\n",
    "- Clusters captured broad differences (hate vs. neutral) but struggled to separate hate from offensive tweets, confirming the linguistic overlap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] Christopher M. Bishop. Neural Networks for Pattern Recognition. Oxford University Press, 1995.<br><br>\n",
    "[2] Christopher Bishop. Pattern Recognition and Machine Learning. Springer, 2006. isbn: 0387310738.<br><br>\n",
    "[3] Barry J. Shepherd C. Wayne Brown. Graphics File Formats: Reference and Guide. Manning\n",
    "Publications, 1995. isbn: 1884777007.<br><br>\n",
    "[4] Thomas H. Cormen et al. Introduction to Algorithms. 3rd. MIT Press, 2009. isbn: 780262033848.<br><br>\n",
    "[5] W. R. Dillon and M. Goldstein. Multivariate Analysis Method and Applications. New York, NY:\n",
    "John Wiley Sons, Inc, 1984.<br><br>\n",
    "[6] Richard O. Duda, Peter E. Hart, and David G. Stork. Pattern Classification. 2nd. Wiley-\n",
    "Interscience, 2000.<br><br>\n",
    "[7] Duin et al. PRTools. https://cmp.felk.cvut.cz/cmp/software/stprtool/index.html.<br><br>\n",
    "[8] L. Euler. Nova Acta Acad. Sci. Petrop. In: (1960).<br><br>\n",
    "[9] R.A. Fisher. The use of Multiple Measurements in Taxonomic Problems. In: Proceedings of\n",
    "Annals of Eugenics 7 (1936), pp. 179188.<br><br>\n",
    "[10] Vojtech Franc and Vaclav Hlavac. Statistical Pattern Recognition Toolbox. https://cmp.felk.\n",
    "cvut.cz/cmp/software/stprtool/index.html.<br><br>\n",
    "[11] Keinosuke Fukunaga. Introduction to Statistical Pattern Recognition. 1st. Academic Press, 1972.\n",
    "isbn: 0122698509.<br><br>\n",
    "[12] Keinosuke Fukunaga. Introduction to Statistical Pattern Recognition. 2nd. Academic Press, 1990.\n",
    "isbn: 0122698517.<br><br>\n",
    "[13] Herman H. Goldstine. A History of Numerical Analysis from the 16th through the 19th Century.\n",
    "Springer New York, 1977. isbn: 978-0-387-90277-7.<br><br>\n",
    "[14] H. Hotelling. Analysis of a complex of statistical variables into principal components. In: Jour-\n",
    "nal of Educational Psychology 24 (1933), pp. 417441.<br><br>\n",
    "[15] Averill Law. Simulation Modeling and Analysis. 5th. Mcgraw-hill Series in Industrial Engineering\n",
    "and Management, 2014.<br><br>\n",
    "[16] Machine Learning at Waikato University. https://www.cs.waikato.ac.nz/~ml/index.html.<br><br>\n",
    "[17] James D. Murry and William vanRyper. Encyclopedia of Graphics File Formats: The Com-\n",
    "plete Reference on CD-ROM with Links to Internet Resources. 2nd. OReilly Media, 1996. isbn:\n",
    "1565921615.<br><br>\n",
    "[18] F. Pedregosa et al. Scikit-learn: Machine Learning in Python. In: Journal of Machine Learning\n",
    "Research 12 (2011), pp. 28252830.<br><br>\n",
    "[19] Casey J. Richards et al. Multimodal data fusion using signal/image processing methods for\n",
    "multi-class machine learning. In: Signal Processing, Sensor/Information Fusion, and Target\n",
    "Recognition XXXII. Ed. by Ivan Kadar, Erik P. Blasch, and Lynne L. Grewe. Vol. 12547. Inter-\n",
    "national Society for Optics and Photonics. SPIE, 2023, 125470N. doi: 10.1117/12.2664987.\n",
    "url: https://doi.org/10.1117/12.2664987.<br><br>\n",
    "[20] Benjamin M. Rodriguez. Multi-Class Classification for Identifying JPEG Steganography Em-\n",
    "bedding Methods. PhD thesis. Air Force Institute of Technology, 2008. url: https://scholar.\n",
    "afit.edu/cgi/viewcontent.cgi?article=3642&context=etd.<br><br>\n",
    "[21] Stuart Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. 4th. Prentice Hall,\n",
    "2020.<br><br>\n",
    "[22] Amir Saeed et al. Reinforcement learning application to satellite constellation sensor tasking.\n",
    "In: Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications V.\n",
    "Ed. by Latasha Solomon and Peter J. Schwartz. Vol. 12538. International Society for Optics and\n",
    "Photonics. SPIE, 2023, 125381B. doi: 10.1117/12.2664346. url: https://doi.org/10.1117/\n",
    "12.2664346.<br><br>\n",
    "[23] C. E. Shannon. Programming a Computer for Playing Chess. In: Philosophical Magazine.\n",
    "7th ser. 41.314 (1950).<br><br>\n",
    "[24] Richard S. Sutton and Andrew G. Barto. Reinforcement learning: An introduction. MIT Press,\n",
    "2018.<br><br>\n",
    "[25] Sergios Theodoridis and Konstantinos Koutroumbas. Pattern Recognition. 3rd. Academic Press,\n",
    "2006. isbn: 0123695317.<br><br>\n",
    "[26] Alan M. Turing. Computing Machinery and Intelligence. In: Mind 59.236 (1950), pp. 433 460.<br><br>\n",
    "[27] P. Winston. Artificial Intelligence. 3rd. Pearson, 1992.<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
