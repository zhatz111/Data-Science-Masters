{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this module you will be exposed to the following topics:\n",
    "\n",
    "- Understanding of Data (Data Types and Formats)\n",
    "- Data Collection\n",
    "- Data Cleaning\n",
    "- Data Transforms\n",
    "- Feature Engineering\n",
    "- Outlier Removal Methodologies\n",
    "- FEature Ranking and Selection\n",
    "- Dimensionality Reduction\n",
    "\n",
    "As you begin to utilize these in your data science process it will be important to understand how to put these into a processing pipeline. With machine learning techniques you will need to repeat the same processing steps for your train data and your test data. A processing pipeline allows for sequential processing of your data where the output of each step becomes the input for the next step. The pipeline should be configurable and extensible. \n",
    "\n",
    "You will use the below dataset that is split into train and test and you will implement a data pipeline using at least two processing steps. You may use the built in methods in sklearn for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120, 4)\n",
      "X_test shape: (30, 4)\n",
      "y_train shape: (120,)\n",
      "y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target labels\n",
    "\n",
    "# Perform an 80-20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets to verify the split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline with at least two processing steps\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create a pipeline using sklearns built in functions\n",
    "# The pipeline will first scale the data, perform dimensionality reduction using\n",
    "# linear discriminant analysis and then SVR to predict\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"fdr\", LinearDiscriminantAnalysis()), (\"svr\", SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629204082292905"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the training data using the pipeline\n",
    "# Sklearn makes the syntax very easy to fit the training data\n",
    "# I use the score method to understand how well the model fits to the\n",
    "# training data.\n",
    "train_fit = pipe.fit(X=X_train, y=y_train)\n",
    "train_fit.score(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735754216423476"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pipeline to transform the test data (X_test)\n",
    "# Using the same pipeline I simply fit the test data\n",
    "# I then use the score method again for the test prediction\n",
    "# The model seems to perform even better than during training\n",
    "test_fit = train_fit.fit(X_test, y_test)\n",
    "test_fit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add your Jupyter Notebook in HTML format to the discussion board found under Module 3. You are encouraged to review other students' submissions to check and discuss differences in your approaches. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
