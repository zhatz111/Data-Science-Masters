{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Analysis\n",
    "\n",
    "- Constant Time (O(1)): Regardless of the input size, the algorithm takes a constant amount of time to complete.\n",
    "    - Accessing an element in an array by index.\n",
    "    - Inserting or deleting an element at the beginning of a linked list.\n",
    "\n",
    "\n",
    "- Linear Time (O(n)): The runtime grows linearly with the size of the input.\n",
    "    - Iterating through a list or array once.\n",
    "    - Searching for an element in an unsorted list by traversing it.\n",
    "\n",
    "\n",
    "- Logarithmic Time (O(log n)): As the input size grows, the runtime increases logarithmically.\n",
    "    - Binary search in a sorted array.\n",
    "    - Operations in a balanced binary search tree (BST).\n",
    "    \n",
    "\n",
    "- Quadratic Time (O(n^2)): The runtime grows quadratically with the input size.\n",
    "    - Nested loops where each loop iterates through the input.\n",
    "    - Some sorting algorithms like Bubble Sort or Selection Sort.\n",
    "\n",
    "\n",
    "- Exponential Time (O(2^n)): The runtime doubles with each addition to the input size.\n",
    "    - Algorithms involving recursive solutions that make repeated calls.\n",
    "    - Solving the Traveling Salesman Problem using brute force.\n",
    "    \n",
    "\n",
    "- Factorial Time (O(n!)): The runtime grows factorially with the input size.\n",
    "    - Permutation problems that explore all possible combinations, like the brute force solution for the Traveling Salesman Problem with no optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples \n",
    "\n",
    "1. Bubble Sort (O(n^2)): Simple sorting algorithm with poor performance but easy to understand. Helpful for understanding quadratic time complexity.\n",
    "\n",
    "2. Merge Sort (O(n log n)): A divide-and-conquer sorting algorithm. Great for understanding logarithmic time complexity.\n",
    "\n",
    "3. Binary Search (O(log n)): Efficient search algorithm for sorted arrays. Perfect for understanding logarithmic time complexity.\n",
    "\n",
    "4. Linear Search (O(n)): Basic search algorithm for an unsorted list. Demonstrates linear time complexity.\n",
    "\n",
    "5. Selection Sort (O(n^2)): Another simple sorting algorithm that's easy to implement but inefficient. Useful for understanding quadratic time complexity.\n",
    "\n",
    "6. Dijkstra's Algorithm (O(V^2) with arrays, O((V + E) log V) with priority queue): Solves the single-source shortest path problem for a graph with non-negative edge weights. Helps understand various complexities based on implementation choices.\n",
    "\n",
    "7. Floyd-Warshall Algorithm (O(V^3)): Computes all pairs shortest path in a weighted graph. Illustrates cubic time complexity.\n",
    "\n",
    "8. Quick Sort (O(n log n) average, O(n^2) worst-case): Efficient sorting algorithm that uses divide-and-conquer. Good for understanding average-case time complexity and worst-case scenarios.\n",
    "\n",
    "9. Knapsack Problem (Various complexities): Dynamic programming problem with variations leading to different time complexities based on approaches taken.\n",
    "\n",
    "10. Traveling Salesman Problem (Various complexities): Combinatorial optimization problem that can be solved in various ways, each with different time complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bubble Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):  # O(n)\n",
    "        for j in range(0, n-i-1):  # O(n)\n",
    "            if arr[j] > arr[j+1]:  # O(1)\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(n^2)\n",
    "# Big Omega notation: Ω(n)\n",
    "# Big Theta notation: Θ(n^2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- The outer loop iterates 'n' times, where 'n' is the length of the array.\n",
    "- The inner loop also iterates 'n' times in the worst case.\n",
    "- The comparisons and swapping operations inside the inner loop are constant time ('O(1)').\n",
    "\n",
    "This results in a total runtime complexity of O(n^2) in the worst case, Ω(n) in the best case (already sorted), and Θ(n^2) in the average and worst cases, as both loops iterate over the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(arr):\n",
    "    if len(arr) > 1:  # O(1)\n",
    "        mid = len(arr) // 2  # O(1)\n",
    "        left_half = arr[:mid]  # O(mid)\n",
    "        right_half = arr[mid:]  # O(mid)\n",
    "\n",
    "        merge_sort(left_half)  # T(n/2)\n",
    "        merge_sort(right_half)  # T(n/2)\n",
    "\n",
    "        i = j = k = 0  # O(1)\n",
    "\n",
    "        # Merge the two halves\n",
    "        while i < len(left_half) and j < len(right_half):  # O(n)\n",
    "            if left_half[i] < right_half[j]:  # O(1)\n",
    "                arr[k] = left_half[i]  # O(1)\n",
    "                i += 1\n",
    "            else:\n",
    "                arr[k] = right_half[j]  # O(1)\n",
    "                j += 1\n",
    "            k += 1\n",
    "\n",
    "        # Check for remaining elements in left_half\n",
    "        while i < len(left_half):  # O(n)\n",
    "            arr[k] = left_half[i]  # O(1)\n",
    "            i += 1\n",
    "            k += 1\n",
    "\n",
    "        # Check for remaining elements in right_half\n",
    "        while j < len(right_half):  # O(n)\n",
    "            arr[k] = right_half[j]  # O(1)\n",
    "            j += 1\n",
    "            k += 1\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(n log n)\n",
    "# Big Omega notation: Ω(n log n)\n",
    "# Big Theta notation: Θ(n log n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- The algorithm divides the array repeatedly into halves until the base case of having individual elements is reached.\n",
    "- Dividing the array takes constant time, and the recursion occurs log n times (halving the array in each recursive step).\n",
    "- Merging the sorted halves takes linear time ('O(n)'), where 'n' is the total number of elements.\n",
    "\n",
    "Thus, the overall complexity is O(n log n) in all cases—best, average, and worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr, target):\n",
    "    low = 0  # O(1)\n",
    "    high = len(arr) - 1  # O(1)\n",
    "\n",
    "    while low <= high:  # O(log n)\n",
    "        mid = (low + high) // 2  # O(1)\n",
    "        mid_val = arr[mid]  # O(1)\n",
    "\n",
    "        if mid_val == target:  # O(1)\n",
    "            return mid  # O(1)\n",
    "        elif mid_val < target:  # O(1)\n",
    "            low = mid + 1  # O(1)\n",
    "        else:\n",
    "            high = mid - 1  # O(1)\n",
    "\n",
    "    return -1  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(log n)\n",
    "# Big Omega notation: Ω(1)\n",
    "# Big Theta notation: Θ(log n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Binary search operates on a sorted array and continually divides the search interval in half.\n",
    "- The while loop runs in logarithmic time ('O(log n)'), as the search space reduces by half in each iteration.\n",
    "- All other operations within the loop, including comparisons and arithmetic, take constant time ('O(1)').\n",
    "\n",
    "Thus, the overall complexity of binary search is O(log n) in the worst case, Ω(1) in the best case (when the element is found at the middle), and Θ(log n) in the average case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search(arr, target):\n",
    "    for i in range(len(arr)):  # O(n)\n",
    "        if arr[i] == target:  # O(1)\n",
    "            return i  # O(1)\n",
    "    return -1  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(n)\n",
    "# Big Omega notation: Ω(1)\n",
    "# Big Theta notation: Θ(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- The algorithm iterates through the array once using a for loop, which takes linear time ('O(n)') where 'n' is the size of the array.\n",
    "- Each comparison inside the loop takes constant time ('O(1)').\n",
    "\n",
    "The overall complexity of linear search is O(n) in the worst case (when the element is at the end or not present), Ω(1) in the best case (when the target is at the first index), and Θ(n) in the average case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n - 1):  # O(n)\n",
    "        min_index = i  # O(1)\n",
    "        for j in range(i + 1, n):  # O(n)\n",
    "            if arr[j] < arr[min_index]:  # O(1)\n",
    "                min_index = j  # O(1)\n",
    "        arr[i], arr[min_index] = arr[min_index], arr[i]  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(n^2)\n",
    "# Big Omega notation: Ω(n^2)\n",
    "# Big Theta notation: Θ(n^2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Selection sort divides the input list into two parts: the sorted part at the beginning and the unsorted part at the end.\n",
    "- In each iteration of the outer loop, it finds the minimum element from the unsorted part and swaps it with the first unsorted element.\n",
    "- The outer loop runs 'n-1' times, and the inner loop runs 'n' times in the worst case.\n",
    "\n",
    "Overall, the complexity of selection sort is O(n^2) in the worst, best, and average cases because it involves nested loops where each loop iterates through the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dijkstra's Algorithm with Arrays (O(V^2)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the graph is represented as an adjacency matrix 'graph' and 'source' is the starting node\n",
    "def dijkstra_array(graph, source):\n",
    "    vertices = len(graph)\n",
    "    distance = [float('inf')] * vertices  # O(V)\n",
    "    distance[source] = 0  # O(1)\n",
    "    visited = [False] * vertices  # O(V)\n",
    "\n",
    "    for _ in range(vertices):  # O(V)\n",
    "        min_distance = float('inf')\n",
    "        min_index = -1\n",
    "\n",
    "        for v in range(vertices):  # O(V)\n",
    "            if not visited[v] and distance[v] < min_distance:  # O(1)\n",
    "                min_distance = distance[v]  # O(1)\n",
    "                min_index = v  # O(1)\n",
    "\n",
    "        visited[min_index] = True  # O(1)\n",
    "\n",
    "        for v in range(vertices):  # O(V)\n",
    "            if not visited[v] and graph[min_index][v] != 0 and distance[min_index] != float('inf') and distance[min_index] + graph[min_index][v] < distance[v]:  # O(1)\n",
    "                distance[v] = distance[min_index] + graph[min_index][v]  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(V^2)\n",
    "# Big Omega notation: Ω(V^2)\n",
    "# Big Theta notation: Θ(V^2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "In this implementation, the distances are updated using arrays and searching for the minimum distance vertex takes O(V) time, and updating neighbors takes O(V) time.\n",
    "\n",
    "Overall, the complexity is O(V^2) in the worst case when the graph is represented using arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dijkstra's Algorithm with Priority Queue (O((V + E) log V)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "# Assuming the graph is represented as an adjacency list 'graph' and 'source' is the starting node\n",
    "def dijkstra_priority_queue(graph, source):\n",
    "    vertices = len(graph)\n",
    "    distance = [float('inf')] * vertices  # O(V)\n",
    "    distance[source] = 0  # O(1)\n",
    "    visited = [False] * vertices  # O(V)\n",
    "    pq = [(0, source)]  # O(1)\n",
    "  \n",
    "    while pq:  # O((V + E) log V)\n",
    "        dist, u = heapq.heappop(pq)  # O(log V)\n",
    "        visited[u] = True  # O(1)\n",
    "        \n",
    "        for v, weight in graph[u]:  # O(E)\n",
    "            if not visited[v] and dist + weight < distance[v]:  # O(1)\n",
    "                distance[v] = dist + weight  # O(1)\n",
    "                heapq.heappush(pq, (distance[v], v))  # O(log V)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O((V + E) log V)\n",
    "# Big Omega notation: Ω((V + E) log V)\n",
    "# Big Theta notation: Θ((V + E) log V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- This version utilizes a priority queue (heapq in Python) to efficiently select the next node to visit based on the minimum distance.\n",
    "- The priority queue reduces the complexity to O((V + E) log V) because each edge is processed at most twice (once for each node).\n",
    "\n",
    "The overall complexity is O((V + E) log V) in the worst case for graphs represented using a priority queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floyd Warshall Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the graph is represented as an adjacency matrix 'graph'\n",
    "def floyd_warshall(graph):\n",
    "    vertices = len(graph)\n",
    "    \n",
    "    # Initialize the distance matrix with the graph values\n",
    "    distance = [row[:] for row in graph]  # O(V^2)\n",
    "\n",
    "    for k in range(vertices):  # O(V)\n",
    "        for i in range(vertices):  # O(V)\n",
    "            for j in range(vertices):  # O(V)\n",
    "                distance[i][j] = min(distance[i][j], distance[i][k] + distance[k][j])  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(V^3)\n",
    "# Big Omega notation: Ω(V^3)\n",
    "# Big Theta notation: Θ(V^3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- The algorithm updates the distance matrix by considering all pairs of vertices through intermediate vertices.\n",
    "- There are three nested loops, each running 'V' times, leading to a cubic time complexity of O(V^3).\n",
    "\n",
    "The overall complexity is O(V^3) in the worst, best, and average cases for graphs represented using the adjacency matrix in the Floyd-Warshall Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knapsack Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_01(values, weights, capacity):\n",
    "    n = len(values)\n",
    "    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]  # O(n * capacity)\n",
    "\n",
    "    for i in range(1, n + 1):  # O(n)\n",
    "        for w in range(1, capacity + 1):  # O(capacity)\n",
    "            if weights[i - 1] <= w:  # O(1)\n",
    "                dp[i][w] = max(values[i - 1] + dp[i - 1][w - weights[i - 1]], dp[i - 1][w])  # O(1)\n",
    "            else:\n",
    "                dp[i][w] = dp[i - 1][w]  # O(1)\n",
    "\n",
    "    return dp[n][capacity]  # O(1)\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O(n * capacity)\n",
    "# Big Omega notation: Ω(n * capacity)\n",
    "# Big Theta notation: Θ(n * capacity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- The algorithm uses dynamic programming to solve the 0/1 Knapsack Problem.\n",
    "- It constructs a table (dp) to store the maximum values that can be achieved for different capacities and items.\n",
    "- The nested loops iterate over 'n' items and 'capacity', resulting in a complexity of O(n * capacity).\n",
    "\n",
    "For other variations like the unbounded knapsack problem or fractional knapsack problem, the complexities might differ. The unbounded knapsack problem has a pseudo-polynomial time complexity, while the fractional knapsack problem is solvable in linear time. The complexities depend on the specific approach used for each variation of the Knapsack Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traveling Salesman Brute Force Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def traveling_salesman_brute_force(graph):\n",
    "    num_nodes = len(graph)\n",
    "    all_nodes = set(range(num_nodes))\n",
    "    min_cost = float('inf')\n",
    "    min_path = None\n",
    "\n",
    "    for path in itertools.permutations(range(1, num_nodes)):  # O((n-1)!)\n",
    "        cost = 0\n",
    "        current_node = 0\n",
    "        for next_node in path:  # O(n)\n",
    "            cost += graph[current_node][next_node]  # O(1)\n",
    "            current_node = next_node\n",
    "        cost += graph[current_node][0]  # Return to starting node\n",
    "        if cost < min_cost:  # O(1)\n",
    "            min_cost = cost  # O(1)\n",
    "            min_path = (0,) + path + (0,)  # O(n)\n",
    "\n",
    "    return min_cost, min_path\n",
    "\n",
    "# Total Runtime Complexity:\n",
    "# Big O notation: O((n-1)!)\n",
    "# Big Omega notation: Ω((n-1)!)\n",
    "# Big Theta notation: Θ((n-1)!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- This brute-force approach iterates through all permutations of nodes except the starting node (0).\n",
    "- It computes the cost for each permutation by traversing the graph, finding the total distance for each possible path.\n",
    "- The complexity is factorial (O((n-1)!)) as it explores all possible permutations, making it computationally expensive for larger 'n'.\n",
    "\n",
    "For larger instances of the TSP, more efficient algorithms like Dynamic Programming (with memoization), Approximation algorithms (e.g., Nearest Neighbor), or Heuristic methods (e.g., Genetic Algorithms) are used to reduce the complexity. These alternative approaches aim to find suboptimal solutions in a more reasonable time frame compared to the brute-force method. Each method has its own complexity depending on the specifics of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Activity\n",
    "\n",
    "Now that you have been shown a few examples of algorithm analysis, you will do the same for the following algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insertion Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heap Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add your Jupyter Notebook to the discussion board found under Module 1. You are encouraged to review other students' submissions to check and discuss differences in your approaches. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
